---
title: "監視設計の勘所"
free: true
---
# クラウドサービスの監視事情について
近年、AWSやGCPを代表に、クラウドでシステムを構築することは一般的なものになっています。
これらクラウドを利用するにあたって、システムの運用者が考えなければならないものの一つにコストが存在します。
当たり前ですが、無料で使える枠というのはとても限られているものであり、それを超えると際限なく課金されていきます。ビジネスが軌道にのってから放置していたらとんでもない金額を無為に払っていた、なんて話もよく聞くようになりました。

…監視の本なのに、真っ先にコストの話が出てくることに疑問を持たれたでしょうか。もしそうであれば、あなたがこの本を取られたことには意味があったということです。

クラウドサービスにおいてコストを発生する要因はたくさんあります。例えば、CPU,メモリ,通信容量,APIコール回数,そして、ディスクです。
監視をクラウドで構築するにあたってまず考慮する必要があるポイントの一つは、実はコストです。設定を誤ればあっという間に高額請求につながる事があるので、よく理解して使用する必要があります。

## ログファイルを使った監視の特性

ログ監視においては、ディスク容量が問題となります。AWSにおいて、ログを監視するためには「CloudWatch Logs」を利用します。課金対象は「収集(0.76USD/1GB)」「保存(0.033USD/1GB)」「分析((0.0076USD/1GB)」の3工程それぞれで行われ、1GBあたりいくら、と決まっています。(料金は2022/09/25時点)

すなわち、何も考えずログをCloudWatchに流す場合、アプリケーションのスケールアウトとともにCloudWatchの支払い料金も増大します。
もちろん、監査という観点でアプリケーションログやアクセスログを一定期間保存する要件があったりしますので、それ自体が無駄になるということではありません。  
しかし、そもそも収集させるコストが一番高い以上、適当なログを出すのはやめにしたいところです。

今、あなたの管理するプロダクトは1日にどれくらいのログを作成するでしょうか。数十メガバイトであれば、このようなことは気にせずCloudWatchにぶん投げてしまえば良い、そう思われるのもわかります。

ですが、そのアプリケーションに成長の可能性はないのでしょうか。
一度軌道に乗って動き始めたアプリケーションの監視を再び整備することは簡単なことではありません。
あなたのプロダクトが大いにバズって、スケールアウトさせたコンテナそれぞれが数GBのログファイルを毎日CloudWatchに送る状況を想像してみましょう。  
しかも、そのログの大半は「可視化」したり「統計」して使ったりすることのできない、ただエラー観測のためだけの文字列だとしたら？ つまり、`cat xxx.log | grep 'hogehoge'` で事足りるようなログが大半をしめている状態であれば、CloudWatchに連携するのは富豪のやることです。
(最悪なことに、不謹慎な輩のDOS攻撃によってログファイルが肥大化してしまうという可能性だってあります)

また、Cloudwatch logでアラートを作成する場合、送信したログをメトリクス化するようにCloudWatchに設定を行います。
この方法は「[フィルターを使用したログイベントからのメトリクスの作成](フィルターを使用したログイベントからのメトリクスの作成)」で解説されています。

つまり、CloudWatchに送信したログから、ある特定条件に当てはまるログを取得したり、ログに含まれる文字列を取り出したりして「メトリクス化」し、それをアラートに利用するのです。
このため、「文字列」を頑張ってアプリケーションログから拾って監視しようとすると、ログフォーマットとCloudWatchの設定の間に管理しづらい「依存」が生まれる点にも留意する必要があります。  
(アプリケーション側でログの形式を変えたら監視に引っかからなくなった、など)

ここまでに述べたとおり、ログファイルによる監視は汎用性が高い一方、規模が大きくなってくると費用面でも運用面でもコストは高く付きやすい傾向があります。

### 愚直な監視の例
上記で記載の通り、ログファイルを使ったとしても、「メトリクス」による監視を設計できていれば、スマートな監視が可能です。
すなわち、
- どのようなエラーがいつ発生したか。またその発生数はどの程度か
- サーバに来ている通信のURIごとのRPSはどのようになるか。またレスポンス速度との相関はどうなるか
- xxxのアクション数は具体的に何回行われたか

など、様々な値の監視が可能です。アプリケーションログだけでなく、nginxやapacheのアクセスログをメトリクス化するとより多くの情報が得られるでしょう。

しかし、古き良き愚直な監視はこのようになっていません。`fluentd` などで頑張ってログを集積したとして、たとえばアラートのルールが下記のようになっていればなんの意味もないのです。

- 「ERROR」という文字列を含むメッセージが10分の間に3回発生したらアラート
- 「HogeHogeException」という文字列を含むメッセージが...

こういった監視を行うことのメリットは「用意と実装が楽」であることです。  
しかし残念ながら、アプリケーションというのはなかなか複雑なものです。

- 「ERROR」という文字が入るものの、これはアラートにしたくないので例外に指定したい
- 新しい例外を追加したが、アラート設定が不足していてアラートにならなかった結果クレームにつながった
- 恒常的にWARNやERRORが鳴りまくって誰ももう気にしていない
- 例外の数だけアラート設定が必要になって面倒くさい

などはお決まりのパターンでしょう。([書籍「入門監視」](https://amzn.to/3Vfba47)では様々なアンチパターンが紹介されています)  
多くのアプリケーションではERROR,WARN,INFOなどのログレベルを指定できますが、アラートにして対応するものはERRORで、そうでないものはWARNで、、という切り分けはだいたいうまくいきません。  
例えば、ERRORレベルだけど起こる頻度によって区別したいものがあるかもしれません。
逆に、全くログが発生しないことをアラートとして検知したい場合があるかもしれません。

こういったグラデーションに対応するには、最初からログを「メトリクス化」して運用することを考えることが良いと思います。

## メトリクスを使った監視とは
さて、さんざん「メトリクス」という単語を使ってきました。本稿の文脈におけるメトリクスは **「活動を定量化し、その定量化データを集計に使うために加工したデータ」** です。  
例えば、「あるサーバ」の、「あるプログラム」の、書き出した「INFOレベルのログ行数」は1分あたり70回、といったデータです。

「INFOレベルのログ行数」というのがメトリクスの本体で、「70回」というのがその値です。  
「あるサーバ」、「あるプログラム」というのはグルーピングのタグとして利用される情報です。  
もし、「あるプログラム」という条件をなくせば、「あるサーバ」の「INFOレベルのログ行数」を集計することになるので、複数のプログラムがINFOログを書き出していれば、「70回」以上の値になるでしょう。

メトリクスを使った監視とは、「あるメトリクスを定期的に観測し、メトリクスの示す値、またはその値で計算された結果を監視、記録」することで状況を判断するものです。
値の持ち方には種類がありますが、「時系列データ」かつ、「グラフ化可能な数値データ」であることは共通します。

例えば、ERRORレベルのログが発生したとしましょう。これだけでは数値データにはなりませんが、timestampと、ERRORレベルのログカウンタとして定義すれば「ERRORログが何年何月何日 何時何分何秒 に 1回」発生したというメトリクスになります。  
さらに、ログ設計段階で、WARNやERRORレベルの例外全てに「エラーコード」を決めていれば、ERRORレベルのログ発生回数には「エラーコード」というタグを付けることができるようになります。  
このようにすれば、アラート発生段階で具体的なエラーコードを知ることができる上、[PagerDuty](https://ja.pagerduty.com/)のようなアラート管理システムと連携することで、エラーコードに従った柔軟な対応をすることが可能になるでしょう。

また、発生頻度をグラフ化することができるので、他のメトリクス(例えばCPU、メモリ使用率、アクセス頻度)と重ね合わせることで、アラートになりやすい状況を推測することができます。  
発想を転換して、1時間の間にこのメトリクスに変化がなければアラートにする、といった事が可能なツールも存在します。

メトリクス監視はログベースの愚直な監視と異なり、アプリケーションの成長度合いやビジネスのKPIの指標を観測することもできます。
たとえば、
- 新規会員の登録数
- 既存会員の離脱数
- APIエンドポイントやサーバレンダリングのURI別レスポンス速度
- ログイン実行回数
などをメトリクスとして保存し、時系列データとして分析することも可能です。
AWS CloudWatchの保存期間は最大で455日間となっています。(ただし、1時間スパンのデータとして集約されるため、細かい情報は見れません)

## CloudWatchのコスト
ぼんやりとメトリクスの姿が見えてきたところで、お金を見ておきましょう。
[CloudWatch](https://aws.amazon.com/jp/cloudwatch/pricing/)の料金表を確認すると、2022/09時点では下記のようになっています。

|内容|料金|
|----------------------------------------|---------------|
|基本モニタリングのメトリクス (5 分間隔)       |無料枠|
|詳細モニタリングのメトリクス 10 個 (1 分間隔) |無料枠|
|100 万の API リクエスト                    |無料枠|
|最初の 10,000 メトリクス                   |0.30USD(メトリクス/月)|
|次の 240,000 メトリクス                    |0.10USD(メトリクス/月)|

これが「高い」となるか「安い」となるかはログ設計次第です。
一つ間違えれば高額請求に繋がりますので、よく理解してから実装しましょう。

### CloudWatchのメトリクスについて
ここで大事なのは、CloudWatchの課金対象としての「メトリクス(ユーザ作成のメトリクス = カスタムメトリクス)」です。

最初のポイントは料金体系にある「0.30USD(メトリクス/月)」の「**月**」です。
つまり、丁寧に書くと、
「1メトリクスを1月、1時間以上停止することなく動かしっぱなしにしたとき、0.30USD」課金されます。

:::message
課金対象が「1時間に1回以上」の単位で、月単位の比例配分になることについては、[CloudWatchの料金計算ページ](https://calculator.aws/#/addService/CloudWatch)のMetricのinfoページに下記の記載があります。

> Metric pricing is prorated by the hour and our calculation assumes customers are sending custom metrics at least once an hour each day of the month.
:::


一般的なメトリクスは動かし続けることに意味があるため、純粋に観測対象となるメトリクス1つにつき0.30USDかかるということになります。
(APIの応答速度など、アクセスの少ない環境下では断続的に出ないものもあるので、一概には言えません。エラーコードも断続的にエラーが出るわけでなければ課金額は時間で按分されるはずです)

さて、ここまでの内容だと、ようはカスタムメトリクスを定義しすぎなければ破産することは無いよね？と思われるでしょう。
しかし、実際はたった一つのメトリクスを定義しただけで破産のリスクがあります。

そのポイントは「ディメンション」です。

### CloudWatchのディメンションとは
実際にメトリクスを運用するとき、`「ERRORログが何年何月何日 何時何分何秒 に N回」` 発生しました、だけでは運用できません。
例えば、どのサーバで発生したのか、どのアプリケーションで発生したのか、即時対応が必要なエラーコードかどうか、、現場によって様々その段階で知りたい情報があるでしょう。

ここで使用できる機能が「[ディメンション](https://dev.classmethod.jp/articles/amazon-cloudwatch-logs-announces-dimension-support-for-metric-filters/)」です。(公式の説明が初心者向けではないので、classmethodさんの記事を紹介させていただきます)

ディメンションはメトリクスに情報を付加することができるKey/Value形式のデータです。
1メトリクスに対して最大30件付与することができます。
例えば、
`「api-server-01」`で、`「LOGIN_TIMEOUT」`エラーコードが、`何年何月何日 何時何分何秒 に N回` 発生しました、というように情報を拡張(タグ付け)することができます。

#### 注意事項/カーディナリティ
ディメンションを利用する際にはカーディナリティに注意を払わなければなりません。
カーディナリティとは、「種類の絶対数」を示します。
例えば、
- 生物学的な性別 = 男女 -> カーディナリティは「2」
- 年間の日数 = 365(うるう年は考慮せず) -> カーディナリティは「365」

となり、カーディナリティが「高い」ほど種類の絶対数が多いと表現します。

ここで先程使用したディメンションをもう少し具体的に考えてみましょう。
例えば、
- サーバ名 -> 20台存在していると仮定 -> カーディナリティは「20」
- エラーコード -> 40種類存在していると仮定 -> カーディナリティは「40」

となります。

さらに、それぞれのサーバでそれぞれのエラーコードが発生すると仮定しましょう。
この場合に設定される可能性のあるカスタムメトリクスの総数は、単純に20 * 40 = 800個(=240USD)という計算結果になります。
(送信されなければ課金されないので、あくまで最悪値です)

このように、ディメンションのカーディナリティが高い場合、設定したカスタムメトリクスがたとえ一つであっても、モニタリングされているカスタムメトリクスとしてはそれなりの量になる可能性があります。
リクエストIDなど、実質ユニークな値をディメンションに指定した日には、ユーザのリクエストごとに課金される事になりかねません。

メトリクスを有効に使うためにも、コストパフォーマンスを意識しましょう。
例えば、サービスの小さなスタートアップであれば、
- サーバのホスト名ではなく、監視対象のアプリケーションの種類でディメンションを作成する
- 何が起きたかというエラーコードではなく、運用の差(想定外エラー、リカバリが必要なエラー、観測だけしたいエラー...)によってエラーコードを作成する

とするほうがよい「かも」しれません。

大規模なアプリケーションを扱っていて、それなりに人数がいて、売上もきちんと立っているアプリケーションであれば、お金が多少かかってもメトリクスの数を増やしたほうがメリットを享受できるはずです。  
リカバリーに何分使えるのか(どの程度の停止が許されるのか)、といったようなサービスの持っている守るべきSLA(Service Level Agreement)と相談しながら決めましょう。

# 監視設計
なるべく監視のコストパフォーマンスを上げるためには、ログファイルとメトリクスの責務をなるべく分離する事が重要になります。

|ログファイル|比較対象|メトリクス
|-------|-------|----------|
|多い    |**情報量**  |少ない     |
|難しい  |**分析**    |簡単      |
|アクセス数とともに悪化|**コスト影響**|指標の数とともに悪化|

知りたい情報をメトリクスによってかんたんに知ることができ、必要に応じてログを参照するのがベターでしょう。

愚直なログ監視は、サービスの成長につれてコスト面でも運用面でもチームの足を引っ張るようになります。  
また、育ったアプリケーションに対してログのメトリクス化対応を行うことはそれなりにコストのかかる行為です。手がつけられるうちに考えることをおすすめします。  
これは、アプリケーション上でどういった場合にどんなエラーコードとするかを定める必要があるためです。


AWSにおいて、メトリクスを使った監視を採用する場合、取れる方法としては主に下記のような手段があるようです。
- ログファイルを分析してメトリクス連携する (CloudWatch)
- APIを呼び出してメトリクス連携する (PutMetricDataAPI -> CloudWatch)
- Amazon Managed Service for Prometheus

次の章では、アプリケーションからどのようにしてCloudWatchとメトリクスを連携させるかを学びます。
