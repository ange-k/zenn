---
title: "監視設計の勘所"
free: true
---
# クラウドサービスの監視事情について
近年、AWSやGCPを代表に、クラウドでシステムを構築することは一般的なものになっています。
これらクラウドを利用するにあたって、システムの運用者が考えなければならないものの一つにコストが存在します。
当たり前ですが、無料で使える枠というのはとても限られているものであり、それを超えると際限なく課金されていきます。ビジネスが軌道にのってから放置していたらとんでもない金額を無為に払っていた、なんて話もよく聞くようになりました。

…監視の本なのに、真っ先にコストの話が出てくることに疑問を持たれたでしょうか。もしそうであれば、あなたがこの本を取られたことには意味があったということです。

クラウドサービスにおいてコストを発生する要因はたくさんあります。例えば、CPU,メモリ,通信容量,APIコール回数,そして、ディスクです。
監視をクラウドで構築するにあたってまず考慮する必要があるポイントの一つは、実はコストです。設定を誤ればあっという間に高額請求につながる事があるので、よく理解して使用する必要があります。

## ログファイルを使った監視の特性

ログ監視においては、ディスク容量が問題となります。AWSにおいて、ログを監視するためには「CloudWatch Logs」を利用します。課金対象は「収集(0.76USD/1GB)」「保存(0.033USD/1GB)」「分析((0.0076USD/1GB)」の3工程それぞれで行われ、1GBあたりいくら、と決まっています。(料金は2023/01/06時点)

すなわち、何も考えずログをCloudWatchに流す場合、アプリケーションのスケールアウトとともにCloudWatchの支払い料金も増大します。
もちろん、監査という観点でアプリケーションログやアクセスログを一定期間保存する要件があったりしますので、それ自体が無駄になるということではありません。  
しかし、そもそも収集させるコストが一番高い以上、適当なログを出すのはやめにしたいところです。

今、あなたの管理するプロダクトは1日にどれくらいのログを作成するでしょうか。数十メガバイトであれば、このようなことは気にせずCloudWatchにぶん投げてしまえば良い、そう思われるのもわかります。

ですが、そのアプリケーションに成長の可能性はないのでしょうか。
一度軌道に乗って動き始めたアプリケーションの監視を再び整備することは簡単なことではありません。
あなたのプロダクトが大いにバズって、スケールアウトさせたコンテナそれぞれが数GBのログファイルを毎日CloudWatchに送る状況を想像してみましょう。  
しかも、そのログの大半は「可視化」したり「統計」して使ったりすることのできない、ただエラー観測のためだけの文字列だとしたら？ つまり、`cat xxx.log | grep 'hogehoge'` で事足りるようなログが大半をしめている状態であれば、CloudWatchに連携するのは富豪のやることです。
(最悪なことに、不謹慎な輩のDOS攻撃によってログファイルが肥大化してしまうという可能性だってあります)

また、Cloudwatch logでアラートを作成する場合、送信したログをメトリクス化するようにCloudWatchに設定を行います。
この方法は「[フィルターを使用したログイベントからのメトリクスの作成](フィルターを使用したログイベントからのメトリクスの作成)」で解説されています。

つまり、CloudWatchに送信したログから、ある特定条件に当てはまるログを取得したり、ログに含まれる文字列を取り出したりして「メトリクス化」し、それをアラートに利用するのです。
このため、「文字列」を頑張ってアプリケーションログから拾って監視しようとすると、ログフォーマットとCloudWatchの設定の間に管理しづらい「依存」が生まれる点にも留意する必要があります。  
(アプリケーション側でログの形式を変えたら監視に引っかからなくなった、など)

### メトリクス化できるログファイルと、できない(しづらい)ログファイル
AWSにおいて、ログを標準出力させ、CloudWatchに渡し、その内容を監視するのは一般的な方法です。  
しかし、そのログがどのような形式を持っているかによって柔軟にメトリクスを扱えるかどうかが決まります。

ポイントはログが構造化されているか、いないかという一点につきます。古き良きログが持っているログの構造は下記のようなものです。
```
F, [2023-01-02T14:22:36.069938 #1764] FATAL -- : [ad7131fb-6d7d-49a8-a5cf-63d29afd68fb] NoMethodError (undefined method `hoge=' for ...
```

一方、構造化されたログは下記のようなものです。(実際には1行で出てきますので人間には解釈しづらいです。人間はツールからログを見ます。)
```json
{
  "host": "96e9f7d0b7ef",
  "application": "Semantic Logger",
  "environment": "development",
  "timestamp": "2023-01-05T11:13:23.274210Z",
  "level": "info",
  "level_index": 2,
  "pid": 1,
  "thread": "puma srv tp 001",
  "named_tags": {
    "request_id": "ca2c882c-fc2a-470e-af94-f64547c17c3b",
    "ip": "172.22.0.1"
  },
  "name": "UsersController",
  "payload": {
    "type": "message",
    "content": "aiueo"
  }
}
```

古いシステムのログは、コンピュータが理解できるような作りになっておらず、人間が読むことだけを考えたログになっていますが、構造化されたログは機械が読みやすいようにjsonなどの形式を取ります。  
くわえて、1行のログに様々な情報を自動的に付与し、ログを可視化する際の手助けをしてくれます。

このようにログの中にデータが埋め込まれ、正規表現にほぼ頼ることなく細かい情報を取得できてこそ、初めてログのメトリクス化をすすめることができるようになります。

### メトリクスを使った監視と古き監視
メトリクスを使った監視では、下記のようなことがかんたんに実現可能になります。
- どのようなエラーがいつ発生したか。またその発生数はどの程度か
  - ERRORログにエラーコードを紐付けることで「どんなエラーか」を可視化できるようにする
- サーバに来ている通信のURIごとのRPSはどのようになるか
  - ControllerへのIn/Outを見て情報をログに落とすことで、リクエスト数やレスポンス速度の情報を可視化できる
- 会員登録のアクション数や退会のアクションなど重要な導線の数に異常はないか
  - 重要なアクションやトランザクションでログを発生させることで、その頻度や偏りを可視化できる

アプリケーションログだけでなく、nginxやapacheのアクセスログからもメトリクスを取り出すと、より多角的な情報が得られるでしょう

しかし、古き愚直な監視でこのようなことをするのは用意ではありません。  
もし、エンドポイントごとのRPSを算出しようとした場合、エンジニアはアクセスログから当該のエンドポイントをgrepでかき集めてきて時間でソートしてユニークにしてカウントして、、ということを繰り返さなければなりません。  
(まあ、RPSの場合はミドルウェアに付属するログ解析ツールがサポートしてくれることが多いです。アクション数の偏りを調べろと言われる方が面倒くさいかもしれないですね)

アラートにしても、古き監視によくある、下記のようなアラートルールはとても変化に弱いです。
- 「ERROR」という文字列を含むメッセージが10分の間に3回発生したらアラート
- 「HogeHogeException」という文字列を含むメッセージが...

こういった監視を行うことのメリットは「用意と実装が楽」であることです。  
しかし残念ながら、アプリケーションというのはなかなか複雑なものです。

- 「ERROR」という文字が入るものの、これはアラートにしたくないので例外に指定したい
- 新しい例外を追加したが、アラート設定が不足していてアラートにならなかった結果事故につながった
- 恒常的にWARNやERRORが鳴りまくって誰ももう気にしていない
- 例外の数だけアラート設定が必要になって面倒くさい

などはお決まりのパターンでしょう。([書籍「入門監視」](https://amzn.to/3Vfba47)では様々なアンチパターンが紹介されています)  
多くのアプリケーションではERROR,WARN,INFOなどのログレベルを指定できますが、アラートにして対応するものはERRORで、そうでないものはWARNで、、という切り分けはだいたいうまくいきません。  
例えば、ERRORレベルだけど起こる頻度によって区別したいものがあるかもしれません。
逆に、全くログが発生しないことをアラートとして検知したい場合があるかもしれません。

システムが育ち、ビジネスが成熟するにつれて、監視・運用という分野が未熟であると、事あるごとにチームの足を引っ張っていきます。 
構造化ログとメトリクスはは、運用監視に柔軟性と表現力をあたえることで、変化への対応を行うことができます。

## メトリクスを使った監視とは
さて、さんざん「メトリクス」という単語を使ってきました。本稿の文脈におけるメトリクスは **「活動を定量化し、その定量化データを集計に使うために加工したデータ」** です。  
例えば、
- 「あるController」の「あるアクション」の、1分あたり呼び出し回数は1分あたり30回
- 「あるサーバ」の、「あるプログラム」の、書き出した「INFOレベルのログ」は1分あたり70回
といったデータです。

「INFOレベルのログ」というのがメトリクスの本体で、「70回」というのがその値です。  
「あるサーバ」、「あるプログラム」というのはグルーピングのタグとして利用される情報です。  
もし、「あるプログラム」という条件をなくせば、「あるサーバ」の「INFOレベルのログ行数」を集計することになるので、複数のプログラムがINFOログを書き出していれば、「70回」以上の値になるでしょう。

メトリクスを使った監視とは、「あるメトリクスを定期的に観測し、メトリクスの示す値、またはその値で計算された結果を監視、記録」することで状況を判断するものです。
値の持ち方には種類がありますが、「時系列データ」かつ、「グラフ化可能な数値データ」であることは共通します。

例えば、ERRORレベルのログが発生したとしましょう。これだけでは数値データにはなりませんが、timestampと、ERRORレベルのログカウンタとして定義すれば「ERRORログが何年何月何日 何時何分何秒 に 1回」発生したというメトリクスになります。  
さらに、ログ設計段階で、WARNやERRORレベルの例外全てに「エラーコード」を決めていれば、ERRORレベルのログ発生回数には「エラーコード」というタグを付けることができるようになります。  
このようにすれば、アラート発生段階で具体的なエラーコードを知ることができます。より良いログ設計ができていれば、エラーコードと行わなければならない運用は1:1で結び付けられるので、運用の外注も可能になります。  
運用を外注しやすいシステムは、チームへの依存度が低いシステムでもありますので、組織での運用を考えてもメリットがあるでしょう。

また、発生頻度をグラフ化することができるので、他のメトリクス(例えばCPU、メモリ使用率、アクセス頻度)と重ね合わせることで、アラートになりやすい状況を推測することができます。  
発想を転換して、1時間の間にこのメトリクスに変化がなければアラートにする、といった事が可能なツールも存在します。

メトリクス監視はログを正規表現で洗うような愚直な監視と異なり、アプリケーションの成長度合いやビジネスのKPIの指標、SLAを観測することもできます。
たとえば、
- 新規会員の登録数
- 既存会員の離脱数
- APIエンドポイントやサーバレンダリングのURI別レスポンス速度
- ログイン実行回数
などをメトリクスとして保存し、時系列データとして分析することも可能です。
AWS CloudWatchの保存期間は最大で455日間となっています。(ただし、1時間スパンのデータとして集約されるため、細かい情報は見れません)

## CloudWatchのコスト
ぼんやりとメトリクスの姿が見えてきたところで、お金を見ておきましょう。
[CloudWatch](https://aws.amazon.com/jp/cloudwatch/pricing/)の料金表を確認すると、2023/01時点では下記のようになっています。

|内容|料金|
|----------------------------------------|---------------|
|基本モニタリングのメトリクス (5 分間隔)       |無料枠|
|詳細モニタリングのメトリクス 10 個 (1 分間隔) |無料枠|
|100 万の API リクエスト                    |無料枠|
|最初の 10,000 メトリクス                   |0.30USD(メトリクス/月)|
|次の 240,000 メトリクス                    |0.10USD(メトリクス/月)|

これが「高い」となるか「安い」となるかはログ設計次第です。
一つ間違えれば高額請求に繋がりますので、よく理解してから実装しましょう。

### CloudWatchのメトリクスについて
ここで大事なのは、CloudWatchの課金対象としての「メトリクス(ユーザ作成のメトリクス = カスタムメトリクス)」です。

最初のポイントは料金体系にある「0.30USD(メトリクス/月)」の「**月**」です。
つまり、丁寧に書くと、
「1メトリクスを1月、1時間以上停止することなく動かしっぱなしにしたとき、0.30USD」課金されます。

:::message
課金対象が「1時間に1回以上」の単位で、月単位の比例配分になることについては、[CloudWatchの料金計算ページ](https://calculator.aws/#/addService/CloudWatch)のMetricのinfoページに下記の記載があります。

> Metric pricing is prorated by the hour and our calculation assumes customers are sending custom metrics at least once an hour each day of the month.
:::


一般的なメトリクスは動かし続けることに意味があるため、純粋に観測対象となるメトリクス1つにつき0.30USDかかるということになります。
(APIの応答速度など、アクセスの少ない環境下では断続的に出ないものもあるので、一概には言えません。エラーコードも断続的にエラーが出るわけでなければ課金額は時間で按分されるはずです)

さて、ここまでの内容だと、ようはカスタムメトリクスを定義しすぎなければ破産することは無いよね？と思われるでしょう。
しかし、実際はたった一つのメトリクスを定義しただけで破産のリスクがあります。

そのポイントは「ディメンション」です。

### CloudWatchのディメンションとは
実際にメトリクスを運用するとき、`「ERRORログが何年何月何日 何時何分何秒 に N回」` 発生しました、だけでは運用できません。
例えば、どのサーバで発生したのか、どのアプリケーションで発生したのか、即時対応が必要なエラーコードかどうか、、現場によって様々その段階で知りたい情報があるでしょう。

ここで使用できる機能が「[ディメンション](https://dev.classmethod.jp/articles/amazon-cloudwatch-logs-announces-dimension-support-for-metric-filters/)」です。(公式の説明が初心者向けではないので、classmethodさんの記事を紹介させていただきます)

ディメンションはメトリクスに情報を付加することができるKey/Value形式のデータです。
1メトリクスに対して最大30件付与することができます。
例えば、
`「api-server-01」`で、`「LOGIN_TIMEOUT」`エラーコードが、`何年何月何日 何時何分何秒 に N回` 発生しました、というように情報を拡張(タグ付け)することができます。

#### 注意事項/カーディナリティ
ディメンションを利用する際にはカーディナリティに注意を払わなければなりません。
カーディナリティとは、「種類の絶対数」を示します。
例えば、
- 生物学的な性別 = 男女 -> カーディナリティは「2」
- 年間の日数 = 365(うるう年は考慮せず) -> カーディナリティは「365」

となり、カーディナリティが「高い」ほど種類の絶対数が多いと表現します。

ここで先程使用したディメンションをもう少し具体的に考えてみましょう。
例えば、
- サーバ名 -> 20台存在していると仮定 -> カーディナリティは「20」
- エラーコード -> 40種類存在していると仮定 -> カーディナリティは「40」

となります。

さらに、それぞれのサーバでそれぞれのエラーコードが発生すると仮定しましょう。
この場合に設定される可能性のあるカスタムメトリクスの総数は、単純に20 * 40 = 800個(=240USD)という計算結果になります。
(送信されなければ課金されないので、あくまで最悪値です)

このように、ディメンションのカーディナリティが高い場合、設定したカスタムメトリクスがたとえ一つであっても、モニタリングされているカスタムメトリクスとしてはそれなりの量になる可能性があります。
リクエストIDなど、実質ユニークな値をディメンションに指定した日には、ユーザのリクエストごとに課金される事になりかねません。

メトリクスを有効に使うためにも、コストパフォーマンスを意識しましょう。
例えば、
- コンテナ環境ではあまり意味をなさないサーバのホスト名はメトリクスでは監視しない
- 正常系に分類されるようなクライアントエラーではメトリクスを記録しない

のように、運用に意味のあるメトリクスにしていくことが重要です。

大規模なアプリケーションを扱っていて、それなりに人数がいて、売上もきちんと立っているアプリケーションであれば、お金が多少かかってもメトリクスの数を増やしたほうがメリットを享受できるはずです。  
リカバリーに何分使えるのか(どの程度の停止が許されるのか)、といったようなサービスの持っている守るべきSLA(Service Level Agreement)と相談しながら決めましょう。

# 監視設計
なるべく監視のコストパフォーマンスを上げるためには、ログファイルとメトリクスの責務をなるべく分離する事が重要になります。

|ログファイル|比較対象|メトリクス
|-------|-------|----------|
|多い    |**情報量**  |少ない     |
|難しい  |**分析**    |簡単      |
|アクセス数とともに悪化|**コスト影響**|指標の数とともに悪化|

知りたい情報をメトリクスによってかんたんに知ることができ、必要に応じてログを参照するのがベターでしょう。
構造化されたログを検索することは、各サーバにあるログファイルをgrepするよりはかんたんなはずです。

育ったアプリケーションに対してログのメトリクス化対応を行うことはそれなりにコストのかかる行為です。手がつけられるうちに考えることをおすすめします。  
これは、アプリケーション上でどういった場合にどんなエラーコードとするかを定める必要があるためです。

次の章では、アプリケーションからどのようにして構造化ログを送るかを学びます。
