---
title: "監視設計の勘所"
free: true
---
# クラウドサービスの監視事情について
近年、AWSやGCPを代表に、クラウドでシステムを構築することは一般的なものになっています。
これらクラウドを利用するにあたって、システムの運用者が考えなければならないものの一つにコストが存在します。
当たり前ですが、無料で使える枠というのはとても限られているものであり、それを超えると際限なく課金されていきます。ビジネスが軌道にのってから放置していたらとんでもない金額を無為に払っていた、なんて話もよく聞くようになりました。

…監視の本なのに、真っ先にコストの話が出てくることに疑問を持たれたでしょうか。もしそうであれば、あなたがこの本を取られたことには意味があったということです。

クラウドサービスにおいてコストを発生する要因はたくさんあります。例えば、CPU,メモリ,通信容量,APIコール回数,そして、ディスクです。
監視をクラウドで構築するにあたって一番考慮する必要があるポイントの一つは、実はコストです。設定を誤ればあっという間に高額請求につながる事があるので、よく理解して使用する必要があります。

## ログ監視の特性

ログ監視においては、ディスク容量が問題となります。AWSにおいて、ログを監視するためには「CloudWatch Logs」を利用します。課金対象は「収集(0.76USD/1GB)」「保存(0.033USD/1GB)」「分析((0.0076USD/1GB)」の3工程それぞれで行われ、1GBあたりいくら、と決まっています。(料金は2022/09/25時点)

すなわち、何も考えずログをCloudWatchに流す場合、アプリケーションのスケールアウトとともにCloudWatchの支払い料金も増大します。
もちろん、監査という観点でアプリケーションログやアクセスログを一定期間保存する要件があったりしますので、それ自体が無駄になるということではありません。
しかし、考えてほしいのはその観点であれば直接S3へ保存することにより遥かに安い料金で済む(0.025USD/GB)という事実です。

今、あなたの管理するプロダクトは1日にどれくらいのログを作成するでしょうか。数十メガバイトであれば、このようなことは気にせずCloudWatchにぶん投げてしまえば良い、そう思われるのもわかります。

ですが、そのアプリケーションに成長の可能性はないのでしょうか。
一度軌道に乗って動き始めたアプリケーションの監視を再び整備することは簡単なことではありません。
あなたのプロダクトが大いにバズって、スケールアウトさせたコンテナそれぞれが数GBのログファイルを毎日CloudWatchに送る状況を想像してみましょう。
しかも、そのログの大半は「可視化」したり「統計」して使ったりすることのできない、ただエラー観測のためだけの文字列だとしたら？ つまり、`cat xxx.log | grep 'hogehoge'` で事足りるようなログが大半をしめている状態であれば、CloudWatchに連携するのは富豪のやることです。
(最悪なことに、不謹慎な輩のDOS攻撃によってログファイルが肥大化してしまうという可能性だってあります)

また、Cloudwatch logでアラートを作成する場合、送信したログをメトリクス化するようにCloudWatchに設定を行います。
この方法は「[フィルターを使用したログイベントからのメトリクスの作成](フィルターを使用したログイベントからのメトリクスの作成)」で解説されています。

つまり、CloudWatchに送信したログから、ある特定条件に当てはまるログを取得したり、ログに含まれる文字列を取り出したりして「メトリクス化」し、それをアラートに利用するのです。
このため、アプリケーションログフォーマットとCloudWatchの設定の間に管理しづらい「依存」が生まれる点にも留意する必要があります。

ここまでに述べたとおり、ログファイルによる監視は汎用性が高い一方、規模が大きくなってくると費用面でも運用面でもコストは高く付きやすい傾向があります。

## メトリクス監視の特性
メトリクス監視とは、「ある値を定期的に観測し、その値、またはその値で計算された結果を監視」することで状況を判断するものです。
値の持ち方には種類がありますが、「時系列データ」かつ、「グラフ化可能な数値データ」であることは共通します。

例えば、ERRORレベルのログが発生したとしましょう。これだけでは数値データにはなりませんが、timestampと、ERRORレベルのログカウンタとして定義すれば「ERRORログが何年何月何日 何時何分何秒 に 1回」発生したというメトリクスになります。
メトリクスとは、このN回発生した、という指標そのもののことを言っており、たとえ数千回発生したとしても1つのメトリクスで時系列データを表現することができます。

メトリクス監視はログ監視と異なり、アプリケーションの成長度合いやビジネスのKPIの指標を観測することもできます。
たとえば、
- 新規会員の登録数
- 既存会員の離脱数
- APIエンドポイントやサーバレンダリングのURI別レスポンス速度
- ログイン実行回数
などをメトリクスとして保存し、時系列データとして分析することも可能です。
保存期間については、最大で455日間保存されるようです。(ただし、1時間スパンのデータとして集約されるため、細かい情報は見れません)

ぼんやりとメトリクスの姿が見えてきたところで、お金を見ておきましょう。
[CloudWatch](https://aws.amazon.com/jp/cloudwatch/pricing/)の料金表を確認すると、2022/09時点では下記のようになっています。

|内容|料金|
|----------------------------------------|---------------|
|基本モニタリングのメトリクス (5 分間隔)       |無料枠|
|詳細モニタリングのメトリクス 10 個 (1 分間隔) |無料枠|
|100 万の API リクエスト                    |無料枠|
|最初の 10,000 メトリクス                   |0.30USD(メトリクス/月)|
|次の 240,000 メトリクス                    |0.10USD(メトリクス/月)|

これが「高い」となるか「安い」となるかはログ設計次第です。
一つ間違えれば高額請求に繋がりますので、よく理解してから実装しましょう。

### CloudWatchのメトリクスについて
ここで大事なのは、CloudWatchの課金対象としての「メトリクス(ユーザ作成のメトリクス = カスタムメトリクス)」です。

最初のポイントは料金体系にある「0.30USD(メトリクス/月)」の「**月**」です。
つまり、丁寧に書くと、
「1メトリクスを1月、1時間以上停止することなく動かしっぱなしにしたとき、0.30USD」課金されます。

:::message
課金対象が「1時間に1回以上」の単位で、月単位の比例配分になることについては、[CloudWatchの料金計算ページ](https://calculator.aws/#/addService/CloudWatch)のMetricのinfoページに下記の記載があります。

> Metric pricing is prorated by the hour and our calculation assumes customers are sending custom metrics at least once an hour each day of the month.
:::


一般的なメトリクスは動かし続けることに意味があるため、純粋に観測対象となるメトリクス1つにつき0.30USDかかるということになります。

さて、ここまでの内容だと、ようはカスタムメトリクスを定義しすぎなければ破産することは無いよね？と思われるでしょう。
しかし、実際はたった一つのメトリクスを定義しただけで破産のリスクがあります。

そのポイントは「ディメンション」です。

### CloudWatchのディメンションとは
実際にメトリクスを運用するとき、`「ERRORログが何年何月何日 何時何分何秒 に N回」` 発生しました、だけでは運用できません。
例えば、どのサーバで発生したのか、どのアプリケーションで発生したのか、即時対応が必要なエラーコードかどうか、、現場によって様々その段階で知りたい情報があるでしょう。

ここで使用できる機能が「[ディメンション](https://dev.classmethod.jp/articles/amazon-cloudwatch-logs-announces-dimension-support-for-metric-filters/)」です。(公式の説明が初心者向けではないので、classmethodさんの記事を紹介させていただきます)

ディメンションはメトリクスに情報を付加することができるKey/Value形式のデータです。
1メトリクスに対して最大30件付与することができます。
例えば、
`「api-server-01」`で、`「LOGIN_TIMEOUT」`エラーコードが、`何年何月何日 何時何分何秒 に N回` 発生しました、というように情報を拡張することができます。

#### 注意事項/カーディナリティ
ディメンションを利用する際にはカーディナリティに注意を払わなければなりません。
カーディナリティとは、「種類の絶対数」を示します。
例えば、
- 生物学的な性別 -> 男女 -> カーディナリティは「2」
- 年間の日数 -> 365(うるう年は考慮せず) -> カーディナリティは「365」

となり、カーディナリティが「高い」ほど種類の絶対数が多いと表現します。

ここで先程使用したディメンションをもう少し具体的に考えてみましょう。
例えば、
- サーバ名 -> 20台存在していると仮定 -> カーディナリティは「20」
- エラーコード -> 40種類存在していると仮定 -> カーディナリティは「40」

となります。

さらに、それぞれのサーバでそれぞれのエラーコードが発生すると仮定しましょう。
この場合に設定される可能性のあるカスタムメトリクスの総数は、単純に20 * 40 = 800個(=240USD)という計算結果になります。
(送信されなければ課金されないので、あくまで最悪値です)

このように、ディメンションのカーディナリティが高い場合、設定したカスタムメトリクスがたとえ一つであっても、モニタリングされているカスタムメトリクスとしてはそれなりの量になる可能性があります。
リクエストIDなど、実質ユニークな値をディメンションに指定した日には、ユーザのリクエストごとに課金される事になりかねません。

メトリクスを有効に使うためにも、コストパフォーマンスを意識しましょう。
例えば、
- サーバのホスト名ではなく、監視対象のアプリケーションの種類でディメンションを作成する
- 何が起きたかというエラーコードではなく、運用の差(想定外エラー、リカバリが必要なエラー、観測だけしたいエラー...)によってエラーコードを作成しよう


# 監視設計
なるべく監視のコストパフォーマンスを上げるためには、ログファイルとメトリクスの責務をなるべく分離する事が重要になります。
ここまでに述べたとおり、ログ監視とメトリクス監視は下記の特性を持ちます。

|ログ監視|比較対象|メトリクス監視
|-------|-------|----------|
|多い    |**ログの情報量**  |少ない     |
|難しい  |**分析**    |簡単      |
|アクセス数とともに悪化|**コスト影響**|指標の数とともに悪化|

判断基準として、リクエスト増え、アプリケーションがスケールしていく仮定でログ監視のままで大丈夫なのか、というところが一つの判断基準になるでしょう。

とくに、RailsのSQL発行ログなどをログに出したままではログファイルサイズは非常に大きなものになってしまいます。

メトリクス監視を採用する場合、取れる方法としては下記があるでしょう。
- ログファイルを分析してメトリクス連携する
  - ただし、エラー解析に必要なログは別のファイルに吐き出す
- APIを呼び出してメトリクス連携する


次の章では、アプリケーションからどのようにしてCloudWatchとメトリクスを連携させるかを学びます。
